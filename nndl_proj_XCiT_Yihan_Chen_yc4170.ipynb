{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25f213e",
   "metadata": {},
   "source": [
    "# NNDL Project\n",
    "Yihan Chen(yc4170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import string\n",
    "import joblib\n",
    "import tifffile\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "from einops import rearrange\n",
    "from torchvision import models\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "from einops.layers.torch import Rearrange\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "import timm\n",
    "from pprint import pprint\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages for vm\n",
    "# ! pip install timm\n",
    "# ! pip install opencv-python\n",
    "# ! pip install joblib\n",
    "# ! pip install tifffile\n",
    "# ! pip install pandas\n",
    "# ! pip install seaborn\n",
    "# ! pip install einops\n",
    "# ! pip install tqdm\n",
    "# ! pip install efficientnet_pytorch\n",
    "# ! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip image files\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"train_shuffle.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"\")\n",
    "# with zipfile.ZipFile(\"test_shuffle.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a77e7",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test_df = pd.read_csv(\"example_test_submission.csv\")\n",
    "\n",
    "super_mapping = pd.read_csv(\"super_classes_mapping.csv\")\n",
    "sub_mapping = pd.read_csv(\"sub_classes_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ser seed for reproducing\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "debug = False\n",
    "# generate_new = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename({'superclass_index':'label', 'subclass_index':'label2'}, axis='columns')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccb400",
   "metadata": {},
   "source": [
    "### Create New image (for predicting new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee569cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN SECOND TIME\n",
    "\n",
    "# spectrum = [0, 64, 128, 192, 255]\n",
    "# SIZE = 8\n",
    "# index = 6472 #start from 6472.jpg\n",
    "\n",
    "# # Pure -- total 125 images\n",
    "# for r in spectrum:\n",
    "#   for g in spectrum:\n",
    "#     for b in spectrum:\n",
    "#       img = Image.new('RGB', (SIZE, SIZE), color = (r,g,b))\n",
    "#       img.save('train_shuffle/' + str(index) + '.jpg')\n",
    "#       index += 1\n",
    "\n",
    "# # Random -- total 150 images\n",
    "#     # colorful -- 50 imagess\n",
    "#     # grey -- 50 images\n",
    "#     # black&white -- 50 images\n",
    "# for i in range(50):\n",
    "#   imarray = np.random.rand(SIZE,SIZE,3) * 255\n",
    "#   im = Image.fromarray(imarray.astype('uint8')).convert('RGB')\n",
    "#   im.save('train_shuffle/' + str(index) + '.jpg')\n",
    "#   index += 1\n",
    "#   im2 = im.convert(\"L\")\n",
    "#   im2.save('train_shuffle/' + str(index) + '.jpg')\n",
    "#   index += 1\n",
    "#   im3 = im2.convert(\"1\")\n",
    "#   im3.save('train_shuffle/' + str(index) + '.jpg')\n",
    "#   index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sub = copy.deepcopy(train_df)\n",
    "for i in range(6472,6747):\n",
    "    train_df_sub.loc[i] = {'image': str(i) + '.jpg', 'label': 3, 'label2': 89}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of images\n",
    "_, _, files = next(os.walk(\"/home/ecbm4040/train_shuffle\"))\n",
    "file_count = len(files)\n",
    "file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check train_df & train_df_sub\n",
    "train_df, train_df_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c266146",
   "metadata": {},
   "source": [
    "### Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        self.train = 'label' in df.columns    \n",
    "\n",
    "    def __len__(self): return len(self.df)    \n",
    "    def __getitem__(self, index):\n",
    "        paths = [\"test_shuffle/\", \"train_shuffle/\"]\n",
    "\n",
    "        image = cv2.imread(paths[self.train] + self.df.iloc[index].image)\n",
    "        \n",
    "        # add transform\n",
    "        image = Image.fromarray(image)\n",
    "#         image = F.adjust_contrast(image, 1.2)\n",
    "#         image = F.adjust_brightness(image, 1.1)\n",
    "        image = F.adjust_sharpness(image, 1.1)\n",
    "        image = np.array(image)\n",
    "        \n",
    "        image = cv2.resize(image, (512, 512)).transpose(2, 0, 1)\n",
    "\n",
    "        label = None\n",
    "        if self.train:\n",
    "          label = self.df.iloc[index].label\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4c2e2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e830fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.cuda()       \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "               \n",
    "            epoch_loss = 0.0\n",
    "            epoch_acc = 0\n",
    "            \n",
    "            dataloader = dataloaders_dict[phase]\n",
    "            for item in tqdm(dataloader, leave=False):\n",
    "                images = item[0].cuda().float()\n",
    "                classes = item[1].cuda().long()\n",
    "                optimizer.zero_grad()                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(images)\n",
    "                    loss = criterion(output, classes)\n",
    "                    _, preds = torch.max(output, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    epoch_loss += loss.item() * len(output)\n",
    "                    epoch_acc += torch.sum(preds == classes.data)                    \n",
    "            data_size = len(dataloader.dataset)\n",
    "            epoch_loss = epoch_loss / data_size\n",
    "            epoch_acc = epoch_acc.double() / data_size\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')    \n",
    "        if epoch_acc > best_acc:\n",
    "            torch.save(model.state_dict(), \"model_state.pth\")\n",
    "#             traced = torch.jit.trace(model.cpu(), torch.rand(1, 3, 512, 512))\n",
    "#             traced.save('model.pth')\n",
    "            best_acc = epoch_acc\n",
    "    print()\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = timm.list_models(pretrained=True)\n",
    "# pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdc9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_CONSOLE'] = 'off'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4bdde",
   "metadata": {},
   "source": [
    "## XCiT - Super Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20022bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xcit_nano_12_p16_384_dist Epoch 1/1 |  val  | Loss: 3.8789 | Acc: 0.5200\n",
    "\n",
    "model = timm.create_model('xcit_nano_12_p16_384_dist')\n",
    "train, val = train_test_split(train_df, test_size=0.2, random_state=42, stratify = train_df.label)\n",
    "test_0, val = train_test_split(val, test_size=0.5, random_state=42, stratify = val.label)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(ImgDataset(train), batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "val_loader = DataLoader(ImgDataset(val), batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4/2)\n",
    "# weight_decay (float, optional) – weight decay coefficient (default: 1e-2)\n",
    "train_model(model, dataloaders_dict, criterion, optimizer, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset_test(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        self.train = 'label' in df.columns    \n",
    "\n",
    "    def __len__(self): return len(self.df)    \n",
    "    def __getitem__(self, index):\n",
    "        paths = [\"test_shuffle/\", \"train_shuffle/\"]\n",
    "\n",
    "        image = cv2.imread(paths[self.train] + self.df.iloc[index].image_index)\n",
    "        \n",
    "        # add transform\n",
    "        image = Image.fromarray(image)\n",
    "#         image = F.adjust_contrast(image, 1.2)\n",
    "#         image = F.adjust_brightness(image, 1.1)\n",
    "        image = F.adjust_sharpness(image, 1.1)\n",
    "        image = np.array(image)\n",
    "        \n",
    "        image = cv2.resize(image, (512, 512)).transpose(2, 0, 1)\n",
    "\n",
    "        label = 0 # useless\n",
    "        if self.train:\n",
    "          label = self.df.iloc[index].label\n",
    "        \n",
    "        image_index = self.df.iloc[index].image_index\n",
    "        \n",
    "        return image, image_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    dataloader = dataloader\n",
    "    outputs = []\n",
    "    s = nn.Softmax(dim=1)\n",
    "    ids = []\n",
    "    \n",
    "    for item in tqdm(dataloader, leave=False):\n",
    "        image_index = item[1][0]\n",
    "#         try:\n",
    "        images = item[0].cuda().float()\n",
    "        ids.append(image_index)\n",
    "        output = model(images)\n",
    "        outputs.append(s(output.cpu()[:,:3])[0].detach().numpy())\n",
    "        \n",
    "#         except:\n",
    "#             ids.append(image_index)\n",
    "#             outputs.append(s(torch.tensor([[1, 1]]).float())[0].detach().numpy())\n",
    "    return np.array(outputs), ids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71180f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load('model.pth')\n",
    "model = timm.create_model('xcit_nano_12_p16_384_dist')\n",
    "model.load_state_dict(torch.load(\"model_state.pth\"))\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(\n",
    "    ImgDataset(test_0), \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = 1\n",
    ")\n",
    "test_results_0, ids_0 = predict(model, test_loader)\n",
    "sum(test_results_0.argmax(1) == test_0.label)/len(test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f16bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_loader = DataLoader(\n",
    "    ImgDataset_test(test_df), \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = 1\n",
    ")\n",
    "\n",
    "anss, ids = predict(model, test_loader)\n",
    "res = pd.DataFrame({\"image_index\" : ids, \"superclass_index\" : anss.argmax(1)})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('super_79134.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad9660",
   "metadata": {},
   "source": [
    "## XCiT - Sub Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4cfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sub = train_df_sub.rename({'label':'label2', 'label2':'label'}, axis='columns')\n",
    "train_df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5435f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    dataloader = dataloader\n",
    "    outputs = []\n",
    "    s = nn.Softmax(dim=1)\n",
    "    ids = []\n",
    "    \n",
    "    for item in tqdm(dataloader, leave=False):\n",
    "        image_index = item[1][0]\n",
    "#         try:\n",
    "        images = item[0].cuda().float()\n",
    "        ids.append(image_index)\n",
    "        output = model(images)\n",
    "        outputs.append(s(output.cpu()[:,:90])[0].detach().numpy())\n",
    "        \n",
    "#         except:\n",
    "#             ids.append(image_index)\n",
    "#             outputs.append(s(torch.tensor([[1, 1]]).float())[0].detach().numpy())\n",
    "    return np.array(outputs), ids \n",
    "\n",
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.cuda()       \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "               \n",
    "            epoch_loss = 0.0\n",
    "            epoch_acc = 0\n",
    "            \n",
    "            dataloader = dataloaders_dict[phase]\n",
    "            for item in tqdm(dataloader, leave=False):\n",
    "                images = item[0].cuda().float()\n",
    "                classes = item[1].cuda().long()\n",
    "                optimizer.zero_grad()                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(images)\n",
    "                    loss = criterion(output, classes)\n",
    "                    _, preds = torch.max(output, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    epoch_loss += loss.item() * len(output)\n",
    "                    epoch_acc += torch.sum(preds == classes.data)                    \n",
    "            data_size = len(dataloader.dataset)\n",
    "            epoch_loss = epoch_loss / data_size\n",
    "            epoch_acc = epoch_acc.double() / data_size\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')    \n",
    "        if epoch_acc > best_acc:\n",
    "            torch.save(model.state_dict(), \"model_state_sub.pth\")\n",
    "#             traced = torch.jit.trace(model.cpu(), torch.rand(1, 3, 512, 512))\n",
    "#             traced.save('model.pth')\n",
    "            best_acc = epoch_acc\n",
    "    print()\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3505af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xcit_nano_12_p16_384_dist Epoch 1/1 |  val  | Loss: 3.8789 | Acc: 0.5200\n",
    "\n",
    "model = timm.create_model('xcit_nano_12_p16_384_dist')\n",
    "train, val = train_test_split(train_df_sub, test_size=0.2, random_state=42, stratify = train_df_sub.label)\n",
    "test_0, val = train_test_split(val, test_size=0.5, random_state=42, stratify = val.label)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(ImgDataset(train), batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "val_loader = DataLoader(ImgDataset(val), batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4/2) \n",
    "# weight_decay (float, optional) – weight decay coefficient (default: 1e-2)\n",
    "sub_model = train_model(model, dataloaders_dict, criterion, optimizer, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('xcit_nano_12_p16_384_dist')\n",
    "model.load_state_dict(torch.load(\"model_state_sub.pth\"))\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(\n",
    "    ImgDataset(test_0), \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = 1\n",
    ")\n",
    "test_results_0, ids_0 = predict(model, test_loader)\n",
    "sum(test_results_0.argmax(1) == test_0.label)/len(test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_loader = DataLoader(\n",
    "    ImgDataset_test(test_df), \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    num_workers = 1\n",
    ")\n",
    "\n",
    "anss, ids = predict(model, test_loader)\n",
    "res = pd.DataFrame({\"image_index\" : ids, \"subclass_index\" : anss.argmax(1)})\n",
    "# res['subclass_index'] = anss.argmax(1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('sub_2074.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stop \n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee012dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "for epoch in np.arange(n_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    validation_loss = validate_one_epoch(model, validation_loader)\n",
    "    if early_stopper.early_stop(validation_loss):             \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
