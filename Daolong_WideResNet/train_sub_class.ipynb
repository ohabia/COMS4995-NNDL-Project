{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b657e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d4d70",
   "metadata": {},
   "source": [
    "# SubClass0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass = 0\n",
    "labels = pd.read_csv('train_label.csv')\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = 'cuda'\n",
    "    else:\n",
    "        dev = 'cpu'\n",
    "    return torch.device(dev)\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images, _ in loader:\n",
    "        images = images.view(images.size(0), images.size(1),-1)\n",
    "        mean +=images.mean(2).sum(0)\n",
    "        std +=images.std(2).sum(0)\n",
    "        total_images_count += images.size(0)\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    return mean, std\n",
    "training_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='super-sub-data/super-sub/0', \n",
    "                                                 transform = training_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=64, shuffle=False)\n",
    "import os\n",
    "folder_path = 'super-sub-data/super-sub/0'\n",
    "folder_contents = os.listdir(folder_path)\n",
    "\n",
    "# Count the number of subfolders in the folder\n",
    "num_subfolders = sum([os.path.isdir(os.path.join(folder_path, item)) for item in folder_contents])\n",
    "\n",
    "# Print the result\n",
    "print(f'There are {num_subfolders} subclasses in class0.')\n",
    "test_path = 'test_shuffle/'\n",
    "train_path = 'super-sub-data/super-sub/0/'\n",
    "number_classes=30+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa387f",
   "metadata": {},
   "source": [
    "# SubClass1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass = 1\n",
    "labels = pd.read_csv('train_label.csv')\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = 'cuda'\n",
    "    else:\n",
    "        dev = 'cpu'\n",
    "    return torch.device(dev)\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images, _ in loader:\n",
    "        images = images.view(images.size(0), images.size(1),-1)\n",
    "        mean +=images.mean(2).sum(0)\n",
    "        std +=images.std(2).sum(0)\n",
    "        total_images_count += images.size(0)\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    return mean, std\n",
    "training_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='super-sub-data/super-sub/1', \n",
    "                                                 transform = training_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=64, shuffle=False)\n",
    "import os\n",
    "folder_path = 'super-sub-data/super-sub/1'\n",
    "folder_contents = os.listdir(folder_path)\n",
    "\n",
    "# Count the number of subfolders in the folder\n",
    "num_subfolders = sum([os.path.isdir(os.path.join(folder_path, item)) for item in folder_contents])\n",
    "\n",
    "# Print the result\n",
    "print(f'There are {num_subfolders} subclasses in class1.')\n",
    "test_path = 'test_shuffle/'\n",
    "train_path = 'super-sub-data/super-sub/1/'\n",
    "number_classes=29+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11b6f1",
   "metadata": {},
   "source": [
    "# SubClass2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b5a456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 subclasses in class2.\n"
     ]
    }
   ],
   "source": [
    "subclass = 2\n",
    "labels = pd.read_csv('train_label.csv')\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = 'cuda'\n",
    "    else:\n",
    "        dev = 'cpu'\n",
    "    return torch.device(dev)\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    for images, _ in loader:\n",
    "        images = images.view(images.size(0), images.size(1),-1)\n",
    "        mean +=images.mean(2).sum(0)\n",
    "        std +=images.std(2).sum(0)\n",
    "        total_images_count += images.size(0)\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    return mean, std\n",
    "training_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='super-sub-data/super-sub/2', \n",
    "                                                 transform = training_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=64, shuffle=False)\n",
    "import os\n",
    "folder_path = 'super-sub-data/super-sub/2'\n",
    "folder_contents = os.listdir(folder_path)\n",
    "\n",
    "# Count the number of subfolders in the folder\n",
    "num_subfolders = sum([os.path.isdir(os.path.join(folder_path, item)) for item in folder_contents])\n",
    "\n",
    "# Print the result\n",
    "print(f'There are {num_subfolders} subclasses in class2.')\n",
    "test_path = 'test_shuffle/'\n",
    "train_path = 'super-sub-data/super-sub/2/'\n",
    "number_classes=30+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36dc2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################tbd\n",
    "mean, std = get_mean_std(train_loader)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0, 180)),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomAutocontrast(p=0.5)\n",
    "    #transforms.RandomEqualize()\n",
    "    #transforms.AugMix(),\n",
    "    #transforms.ToTensor(),\n",
    "    #transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "    \n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(torch.Tensor(mean), torch.Tensor(std)),\n",
    "    \n",
    "    # add contrast\n",
    "    \n",
    "])\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "dataset = torchvision.datasets.ImageFolder(root = train_path, transform = test_transforms)\n",
    "#build my own class\n",
    "#\n",
    "\n",
    "\n",
    "#dataset = torch.utils.data.DataLoader(dataset=dataset, shuffle=True)\n",
    "\n",
    "# n = len(dataset)  # total number of examples\n",
    "# n_test = int(0.13 * n)  # take ~15% for test\n",
    "# test_temp_set = torch.utils.data.Subset(dataset, range(0,n_test))\n",
    "# dev_set = torch.utils.data.Subset(dataset, range(n_test, n))  # take the rest\n",
    "\n",
    "#split data into dev and test\n",
    "len_dev = int(len(dataset)*0.85)\n",
    "len_testtemp = len(dataset)-len_dev\n",
    "test_temp_set, dev_set = torch.utils.data.random_split(dataset, [len_testtemp, len_dev])\n",
    "dataset_duplicate_1 = DatasetFromSubset(dev_set, transform = train_transforms)\n",
    "dataset_duplicate_2 = DatasetFromSubset(dev_set, transform = train_transforms)\n",
    "dataset_duplicate_3 = DatasetFromSubset(dev_set, transform = train_transforms)\n",
    "dev_set = dev_set + dataset_duplicate_1 + dataset_duplicate_2 + dataset_duplicate_3\n",
    "\n",
    "# dev_loader = torch.utils.data.DataLoader(dataset = dev_set, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "#split dev into val and train\n",
    "train_len = int(len(dev_set)*0.85)\n",
    "val_len = len(dev_set)-train_len\n",
    "train_loader, val_loader = torch.utils.data.random_split(dev_set, [train_len, val_len])\n",
    "train_loader = torch.utils.data.DataLoader(train_loader, batch_size=64)\n",
    "val_loader = torch.utils.data.DataLoader(val_loader, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a39786",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e74e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to train subclass  2\n"
     ]
    }
   ],
   "source": [
    "model = models.wide_resnet50_2(pretrained=False)\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_features, number_classes)\n",
    "device = set_device()\n",
    "\n",
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#optimizer = optim = optim.Adam(resnet50_model.parameters(),lr=0.01)\n",
    "\n",
    "print('begin to train subclass ',subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3fd2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#use learning rate scheduler to train the model\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "def evaluate_model_on_test_set(model, criterion,test_loader):\n",
    "    model.eval()\n",
    "    predicted_correctly_on_epoch = 0\n",
    "    total = 0\n",
    "    device = set_device()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total+= labels.size(0)\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            predicted_correctly_on_epoch += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_acc = 100*predicted_correctly_on_epoch/total\n",
    "    print('testing dataset: got %d out of %d images. Accuracy(%.3f%%), validation loss %.3f'\n",
    "             %(predicted_correctly_on_epoch, total, epoch_acc, val_loss))\n",
    "    return epoch_acc, val_loss\n",
    "\n",
    "# Define the learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "#     if epoch < 10:\n",
    "#         return 0.02\n",
    "#     elif epoch < 20:\n",
    "#         return 0.01\n",
    "#     else:\n",
    "#         return 0.001\n",
    "    return 0.01\n",
    "\n",
    "def train_nn(model, train_loader, test_loader, criterion, epochs):\n",
    "    validation_accuracy_array = [0,0,0,0,0,0,0,0,0,0]\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, patience=5,factor=0.5, verbose=True)\n",
    "    device = set_device()\n",
    "    for epoch in range(epochs):        \n",
    "        print('epoch: ',epoch)\n",
    "        model.train()\n",
    "        running_loss=0\n",
    "        running_correct=0\n",
    "        total=0\n",
    "        losses = []\n",
    "        for data in train_loader:\n",
    "\n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total+= labels.size(0)\n",
    "            #plt.imshow(images)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "#             print(outputs.data.shape)\n",
    "#             print(predicted)\n",
    "#             print()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        #print(scheduler.get_lr())\n",
    "        epoch_loss = running_loss/len(train_loader)\n",
    "        epoch_accuracy = 100*running_correct/total\n",
    "        print('training dataset: got %d out of %d images. Accuracy(%.3f%%), epoch loss %.3f'\n",
    "             %(running_correct, total, epoch_accuracy, epoch_loss))\n",
    "        validation_accuracy, val_loss = evaluate_model_on_test_set(model, nn.CrossEntropyLoss(), test_loader)\n",
    "        losses.append(val_loss)\n",
    "        mean_loss = sum(losses)/len(losses)\n",
    "        print(mean_loss)\n",
    "        scheduler.step(mean_loss)\n",
    "        if validation_accuracy > min(validation_accuracy_array):\n",
    "            validation_accuracy_array[epoch%10] = validation_accuracy\n",
    "        else:\n",
    "            print(\"overfitting.(the updated validation accuracy is less than the minimum validation accuracies of last 10 epochs)\")\n",
    "            break\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107772ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 0\n",
    "model_0 = train_nn(model, train_loader, val_loader, loss_function, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bd380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = train_nn(model, train_loader, val_loader, loss_function, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6b9882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "training dataset: got 333 out of 7126 images. Accuracy(4.673%), epoch loss 6.443\n",
      "testing dataset: got 59 out of 1258 images. Accuracy(4.690%), validation loss 3.485\n",
      "tensor(3.4852, device='cuda:0')\n",
      "epoch:  1\n",
      "0.01\n",
      "training dataset: got 341 out of 7126 images. Accuracy(4.785%), epoch loss 3.862\n",
      "testing dataset: got 64 out of 1258 images. Accuracy(5.087%), validation loss 3.371\n",
      "tensor(3.3709, device='cuda:0')\n",
      "epoch:  2\n",
      "0.01\n",
      "training dataset: got 367 out of 7126 images. Accuracy(5.150%), epoch loss 3.460\n",
      "testing dataset: got 58 out of 1258 images. Accuracy(4.610%), validation loss 3.395\n",
      "tensor(3.3947, device='cuda:0')\n",
      "epoch:  3\n",
      "0.01\n",
      "training dataset: got 352 out of 7126 images. Accuracy(4.940%), epoch loss 3.361\n",
      "testing dataset: got 89 out of 1258 images. Accuracy(7.075%), validation loss 3.415\n",
      "tensor(3.4149, device='cuda:0')\n",
      "epoch:  4\n",
      "0.01\n",
      "training dataset: got 413 out of 7126 images. Accuracy(5.796%), epoch loss 3.346\n",
      "testing dataset: got 64 out of 1258 images. Accuracy(5.087%), validation loss 3.360\n",
      "tensor(3.3599, device='cuda:0')\n",
      "epoch:  5\n",
      "0.01\n",
      "training dataset: got 453 out of 7126 images. Accuracy(6.357%), epoch loss 3.293\n",
      "testing dataset: got 68 out of 1258 images. Accuracy(5.405%), validation loss 3.492\n",
      "tensor(3.4919, device='cuda:0')\n",
      "epoch:  6\n",
      "0.01\n",
      "training dataset: got 524 out of 7126 images. Accuracy(7.353%), epoch loss 3.223\n",
      "testing dataset: got 82 out of 1258 images. Accuracy(6.518%), validation loss 3.307\n",
      "tensor(3.3065, device='cuda:0')\n",
      "epoch:  7\n",
      "0.01\n",
      "training dataset: got 537 out of 7126 images. Accuracy(7.536%), epoch loss 3.186\n",
      "testing dataset: got 79 out of 1258 images. Accuracy(6.280%), validation loss 3.563\n",
      "tensor(3.5629, device='cuda:0')\n",
      "epoch:  8\n",
      "0.01\n",
      "training dataset: got 518 out of 7126 images. Accuracy(7.269%), epoch loss 3.175\n",
      "testing dataset: got 120 out of 1258 images. Accuracy(9.539%), validation loss 3.477\n",
      "tensor(3.4771, device='cuda:0')\n",
      "epoch:  9\n",
      "0.01\n",
      "training dataset: got 597 out of 7126 images. Accuracy(8.378%), epoch loss 3.150\n",
      "testing dataset: got 123 out of 1258 images. Accuracy(9.777%), validation loss 3.179\n",
      "tensor(3.1786, device='cuda:0')\n",
      "epoch:  10\n",
      "0.01\n",
      "training dataset: got 635 out of 7126 images. Accuracy(8.911%), epoch loss 3.134\n",
      "testing dataset: got 90 out of 1258 images. Accuracy(7.154%), validation loss 3.409\n",
      "tensor(3.4093, device='cuda:0')\n",
      "epoch:  11\n",
      "0.01\n",
      "training dataset: got 659 out of 7126 images. Accuracy(9.248%), epoch loss 3.117\n",
      "testing dataset: got 95 out of 1258 images. Accuracy(7.552%), validation loss 3.328\n",
      "tensor(3.3284, device='cuda:0')\n",
      "epoch:  12\n",
      "0.01\n",
      "training dataset: got 616 out of 7126 images. Accuracy(8.644%), epoch loss 3.121\n",
      "testing dataset: got 115 out of 1258 images. Accuracy(9.141%), validation loss 3.409\n",
      "tensor(3.4087, device='cuda:0')\n",
      "epoch:  13\n",
      "0.01\n",
      "training dataset: got 664 out of 7126 images. Accuracy(9.318%), epoch loss 3.103\n",
      "testing dataset: got 133 out of 1258 images. Accuracy(10.572%), validation loss 3.187\n",
      "tensor(3.1874, device='cuda:0')\n",
      "epoch:  14\n",
      "0.01\n",
      "training dataset: got 675 out of 7126 images. Accuracy(9.472%), epoch loss 3.091\n",
      "testing dataset: got 133 out of 1258 images. Accuracy(10.572%), validation loss 3.427\n",
      "tensor(3.4270, device='cuda:0')\n",
      "epoch:  15\n",
      "0.01\n",
      "training dataset: got 657 out of 7126 images. Accuracy(9.220%), epoch loss 3.087\n",
      "testing dataset: got 110 out of 1258 images. Accuracy(8.744%), validation loss 3.393\n",
      "tensor(3.3929, device='cuda:0')\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-03.\n",
      "epoch:  16\n",
      "0.005\n",
      "training dataset: got 725 out of 7126 images. Accuracy(10.174%), epoch loss 3.066\n",
      "testing dataset: got 138 out of 1258 images. Accuracy(10.970%), validation loss 3.207\n",
      "tensor(3.2072, device='cuda:0')\n",
      "epoch:  17\n",
      "0.005\n",
      "training dataset: got 740 out of 7126 images. Accuracy(10.385%), epoch loss 3.050\n",
      "testing dataset: got 120 out of 1258 images. Accuracy(9.539%), validation loss 3.240\n",
      "tensor(3.2401, device='cuda:0')\n",
      "epoch:  18\n",
      "0.005\n",
      "training dataset: got 684 out of 7126 images. Accuracy(9.599%), epoch loss 3.045\n",
      "testing dataset: got 137 out of 1258 images. Accuracy(10.890%), validation loss 3.273\n",
      "tensor(3.2735, device='cuda:0')\n",
      "epoch:  19\n",
      "0.005\n",
      "training dataset: got 732 out of 7126 images. Accuracy(10.272%), epoch loss 3.040\n",
      "testing dataset: got 156 out of 1258 images. Accuracy(12.401%), validation loss 3.249\n",
      "tensor(3.2491, device='cuda:0')\n",
      "epoch:  20\n",
      "0.005\n",
      "training dataset: got 747 out of 7126 images. Accuracy(10.483%), epoch loss 3.033\n",
      "testing dataset: got 133 out of 1258 images. Accuracy(10.572%), validation loss 3.180\n",
      "tensor(3.1796, device='cuda:0')\n",
      "epoch:  21\n",
      "0.005\n",
      "training dataset: got 775 out of 7126 images. Accuracy(10.876%), epoch loss 3.020\n",
      "testing dataset: got 152 out of 1258 images. Accuracy(12.083%), validation loss 3.286\n",
      "tensor(3.2862, device='cuda:0')\n",
      "Epoch    22: reducing learning rate of group 0 to 2.5000e-03.\n",
      "epoch:  22\n",
      "0.0025\n",
      "training dataset: got 791 out of 7126 images. Accuracy(11.100%), epoch loss 3.001\n",
      "testing dataset: got 160 out of 1258 images. Accuracy(12.719%), validation loss 3.269\n",
      "tensor(3.2692, device='cuda:0')\n",
      "epoch:  23\n",
      "0.0025\n",
      "training dataset: got 840 out of 7126 images. Accuracy(11.788%), epoch loss 2.990\n",
      "testing dataset: got 133 out of 1258 images. Accuracy(10.572%), validation loss 3.423\n",
      "tensor(3.4235, device='cuda:0')\n",
      "epoch:  24\n",
      "0.0025\n",
      "training dataset: got 836 out of 7126 images. Accuracy(11.732%), epoch loss 2.986\n",
      "testing dataset: got 141 out of 1258 images. Accuracy(11.208%), validation loss 3.372\n",
      "tensor(3.3717, device='cuda:0')\n",
      "epoch:  25\n",
      "0.0025\n",
      "training dataset: got 857 out of 7126 images. Accuracy(12.026%), epoch loss 2.981\n",
      "testing dataset: got 149 out of 1258 images. Accuracy(11.844%), validation loss 3.123\n",
      "tensor(3.1229, device='cuda:0')\n",
      "epoch:  26\n",
      "0.0025\n",
      "training dataset: got 864 out of 7126 images. Accuracy(12.125%), epoch loss 2.971\n",
      "testing dataset: got 158 out of 1258 images. Accuracy(12.560%), validation loss 3.320\n",
      "tensor(3.3199, device='cuda:0')\n",
      "epoch:  27\n",
      "0.0025\n",
      "training dataset: got 874 out of 7126 images. Accuracy(12.265%), epoch loss 2.962\n",
      "testing dataset: got 154 out of 1258 images. Accuracy(12.242%), validation loss 3.249\n",
      "tensor(3.2491, device='cuda:0')\n",
      "epoch:  28\n",
      "0.0025\n",
      "training dataset: got 906 out of 7126 images. Accuracy(12.714%), epoch loss 2.968\n",
      "testing dataset: got 145 out of 1258 images. Accuracy(11.526%), validation loss 3.600\n",
      "tensor(3.5997, device='cuda:0')\n",
      "epoch:  29\n",
      "0.0025\n",
      "training dataset: got 897 out of 7126 images. Accuracy(12.588%), epoch loss 2.956\n",
      "testing dataset: got 147 out of 1258 images. Accuracy(11.685%), validation loss 3.233\n",
      "tensor(3.2328, device='cuda:0')\n",
      "epoch:  30\n",
      "0.0025\n",
      "training dataset: got 939 out of 7126 images. Accuracy(13.177%), epoch loss 2.944\n",
      "testing dataset: got 154 out of 1258 images. Accuracy(12.242%), validation loss 3.340\n",
      "tensor(3.3395, device='cuda:0')\n",
      "epoch:  31\n",
      "0.0025\n",
      "training dataset: got 942 out of 7126 images. Accuracy(13.219%), epoch loss 2.942\n",
      "testing dataset: got 148 out of 1258 images. Accuracy(11.765%), validation loss 3.182\n",
      "tensor(3.1822, device='cuda:0')\n",
      "Epoch    32: reducing learning rate of group 0 to 1.2500e-03.\n",
      "epoch:  32\n",
      "0.00125\n",
      "training dataset: got 984 out of 7126 images. Accuracy(13.809%), epoch loss 2.921\n",
      "testing dataset: got 152 out of 1258 images. Accuracy(12.083%), validation loss 4.165\n",
      "tensor(4.1649, device='cuda:0')\n",
      "epoch:  33\n",
      "0.00125\n",
      "training dataset: got 998 out of 7126 images. Accuracy(14.005%), epoch loss 2.924\n",
      "testing dataset: got 165 out of 1258 images. Accuracy(13.116%), validation loss 3.339\n",
      "tensor(3.3390, device='cuda:0')\n",
      "epoch:  34\n",
      "0.00125\n",
      "training dataset: got 943 out of 7126 images. Accuracy(13.233%), epoch loss 2.911\n",
      "testing dataset: got 153 out of 1258 images. Accuracy(12.162%), validation loss 3.195\n",
      "tensor(3.1953, device='cuda:0')\n",
      "epoch:  35\n",
      "0.00125\n",
      "training dataset: got 960 out of 7126 images. Accuracy(13.472%), epoch loss 2.924\n",
      "testing dataset: got 171 out of 1258 images. Accuracy(13.593%), validation loss 3.285\n",
      "tensor(3.2850, device='cuda:0')\n",
      "epoch:  36\n",
      "0.00125\n",
      "training dataset: got 1007 out of 7126 images. Accuracy(14.131%), epoch loss 2.907\n",
      "testing dataset: got 176 out of 1258 images. Accuracy(13.990%), validation loss 3.253\n",
      "tensor(3.2530, device='cuda:0')\n",
      "epoch:  37\n",
      "0.00125\n",
      "training dataset: got 993 out of 7126 images. Accuracy(13.935%), epoch loss 2.897\n",
      "testing dataset: got 164 out of 1258 images. Accuracy(13.037%), validation loss 3.305\n",
      "tensor(3.3052, device='cuda:0')\n",
      "Epoch    38: reducing learning rate of group 0 to 6.2500e-04.\n",
      "epoch:  38\n",
      "0.000625\n",
      "training dataset: got 1037 out of 7126 images. Accuracy(14.552%), epoch loss 2.880\n",
      "testing dataset: got 168 out of 1258 images. Accuracy(13.355%), validation loss 3.404\n",
      "tensor(3.4044, device='cuda:0')\n",
      "epoch:  39\n",
      "0.000625\n",
      "training dataset: got 1058 out of 7126 images. Accuracy(14.847%), epoch loss 2.877\n",
      "testing dataset: got 188 out of 1258 images. Accuracy(14.944%), validation loss 3.102\n",
      "tensor(3.1020, device='cuda:0')\n",
      "epoch:  40\n",
      "0.000625\n",
      "training dataset: got 1050 out of 7126 images. Accuracy(14.735%), epoch loss 2.864\n",
      "testing dataset: got 175 out of 1258 images. Accuracy(13.911%), validation loss 3.203\n",
      "tensor(3.2028, device='cuda:0')\n",
      "epoch:  41\n",
      "0.000625\n",
      "training dataset: got 1068 out of 7126 images. Accuracy(14.987%), epoch loss 2.869\n",
      "testing dataset: got 187 out of 1258 images. Accuracy(14.865%), validation loss 3.240\n",
      "tensor(3.2399, device='cuda:0')\n",
      "epoch:  42\n",
      "0.000625\n",
      "training dataset: got 1075 out of 7126 images. Accuracy(15.086%), epoch loss 2.853\n",
      "testing dataset: got 185 out of 1258 images. Accuracy(14.706%), validation loss 3.843\n",
      "tensor(3.8433, device='cuda:0')\n",
      "epoch:  43\n",
      "0.000625\n",
      "training dataset: got 1085 out of 7126 images. Accuracy(15.226%), epoch loss 2.856\n",
      "testing dataset: got 183 out of 1258 images. Accuracy(14.547%), validation loss 3.319\n",
      "tensor(3.3189, device='cuda:0')\n",
      "epoch:  44\n",
      "0.000625\n",
      "training dataset: got 1091 out of 7126 images. Accuracy(15.310%), epoch loss 2.841\n",
      "testing dataset: got 177 out of 1258 images. Accuracy(14.070%), validation loss 3.233\n",
      "tensor(3.2326, device='cuda:0')\n",
      "epoch:  45\n",
      "0.000625\n",
      "training dataset: got 1098 out of 7126 images. Accuracy(15.408%), epoch loss 2.834\n",
      "testing dataset: got 184 out of 1258 images. Accuracy(14.626%), validation loss 3.203\n",
      "tensor(3.2032, device='cuda:0')\n",
      "Epoch    46: reducing learning rate of group 0 to 3.1250e-04.\n",
      "epoch:  46\n",
      "0.0003125\n",
      "training dataset: got 1086 out of 7126 images. Accuracy(15.240%), epoch loss 2.828\n",
      "testing dataset: got 208 out of 1258 images. Accuracy(16.534%), validation loss 3.224\n",
      "tensor(3.2237, device='cuda:0')\n",
      "epoch:  47\n",
      "0.0003125\n",
      "training dataset: got 1106 out of 7126 images. Accuracy(15.521%), epoch loss 2.829\n",
      "testing dataset: got 184 out of 1258 images. Accuracy(14.626%), validation loss 3.205\n",
      "tensor(3.2048, device='cuda:0')\n",
      "epoch:  48\n",
      "0.0003125\n",
      "training dataset: got 1150 out of 7126 images. Accuracy(16.138%), epoch loss 2.800\n",
      "testing dataset: got 198 out of 1258 images. Accuracy(15.739%), validation loss 3.298\n",
      "tensor(3.2978, device='cuda:0')\n",
      "epoch:  49\n",
      "0.0003125\n",
      "training dataset: got 1150 out of 7126 images. Accuracy(16.138%), epoch loss 2.808\n",
      "testing dataset: got 177 out of 1258 images. Accuracy(14.070%), validation loss 3.476\n",
      "tensor(3.4755, device='cuda:0')\n",
      "epoch:  50\n",
      "0.0003125\n",
      "training dataset: got 1101 out of 7126 images. Accuracy(15.450%), epoch loss 2.833\n",
      "testing dataset: got 178 out of 1258 images. Accuracy(14.149%), validation loss 3.946\n",
      "tensor(3.9463, device='cuda:0')\n",
      "epoch:  51\n",
      "0.0003125\n",
      "training dataset: got 1134 out of 7126 images. Accuracy(15.914%), epoch loss 2.822\n",
      "testing dataset: got 172 out of 1258 images. Accuracy(13.672%), validation loss 9.401\n",
      "tensor(9.4007, device='cuda:0')\n",
      "Epoch    52: reducing learning rate of group 0 to 1.5625e-04.\n",
      "overfitting.(the updated validation accuracy is less than the minimum validation accuracies of last 10 epochs)\n"
     ]
    }
   ],
   "source": [
    "model_2 = train_nn(model, train_loader, val_loader, loss_function, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02626473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1622, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_temp_loader = torch.utils.data.DataLoader(dataset = test_temp_set, batch_size=64, shuffle=True)\n",
    "model.eval()\n",
    "device = set_device()\n",
    "# Use the model to predict the outputs for the test data\n",
    "predicted_outputs = []\n",
    "true_outputs = []\n",
    "for input_data, target_data in test_temp_loader:\n",
    "    input_data = input_data.to(device)\n",
    "    target_data = target_data.to(device)\n",
    "    # Feed the input data into the model and compute the predicted outputs\n",
    "    output = model(input_data)\n",
    "    _, predicted = torch.max(output.data,1)\n",
    "    # Store the predicted and true outputs\n",
    "    predicted_outputs.append(predicted)\n",
    "    true_outputs.append(target_data)\n",
    "predicted_outputs = torch.cat(predicted_outputs)\n",
    "true_outputs = torch.cat(true_outputs)\n",
    "accuracy = torch.mean((predicted_outputs == true_outputs).to(torch.float))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d405cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('subclass_2_2.pkl', 'wb') as f:\n",
    "    pickle.dump(model_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d2fb1",
   "metadata": {},
   "source": [
    "wide_resnet50_2 15%\n",
    "wide_resnet101_2 9%\n",
    "resnext50_32x4d 13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be093321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17443333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (0.1787+0.1824+0.1622)/3\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ed93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
